llm_chain = LLMChain(
    memory=None,
    callbacks=None,
    callback_manager=None,
    verbose=False,
    tags=None,
    metadata=None,
    prompt=ChatPromptTemplate(
        input_variables=['input', 'chat_history', 'agent_scratchpad'],
        output_parser=None,
        partial_variables={},
        messages=[
            SystemMessagePromptTemplate(
                prompt=PromptTemplate(
                    input_variables=[],
                    output_parser=None,
                    partial_variables={},
                    template=(
                        'Assistant is a large language model trained by OpenAI.\n\n'
                        'Assistant is designed to be able to assist with a wide range of tasks, from answering '
                        'simple questions to providing in-depth explanations and discussions on a wide range of topics. '
                        'As a language model, Assistant is able to generate human-like text based on the input it receives, '
                        'allowing it to engage in natural-sounding conversations and provide responses that are coherent '
                        'and relevant to the topic at hand.\n\n'
                        'Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is '
                        'able to process and understand large amounts of text, and can use this knowledge to provide '
                        'accurate and informative responses to a wide range of questions. Additionally, Assistant is able to '
                        'generate its own text based on the input it receives, allowing it to engage in discussions and '
                        'provide explanations and descriptions on a wide range of topics.\n\n'
                        'Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable '
                        'insights and information on a wide range of topics. Whether you need help with a specific question or '
                        'just want to have a conversation about a particular topic, Assistant is here to assist.'
                    ),
                    template_format='f-string',
                    validate_template=True
                ),
                additional_kwargs={}
            ),
            MessagesPlaceholder(variable_name='chat_history'),
            HumanMessagePromptTemplate(
                prompt=PromptTemplate(
                    input_variables=['input'],
                    output_parser=None,
                    partial_variables={},
                    template=(
                        'TOOLS\n------\n'
                        'Assistant can ask the user to use tools to look up information that may be helpful in answering the users '
                        'original question. The tools the human can use are:\n\n'
                        '> Exemplar: Use this tool to receive the instructors example summary of last week\'s learning materials to '
                        'compare against student reflections\n\n'
                        'RESPONSE FORMAT INSTRUCTIONS\n----------------------------\n\n'
                        'When responding to me, please output a response in one of two formats:\n\n'
                        '**Option 1:**\n'
                        'Use this if you want the human to use a tool.\n'
                        'Markdown code snippet formatted in the following schema:\n\n'
                        '```json\n'
                        '{{\n'
                        '    "action": string, \\ The action to take. Must be one of Exemplar\n'
                        '    "action_input": string \\ The input to the action\n'
                        '}}\n'
                        '```\n\n'
                        '**Option #2:**\n'
                        'Use this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\n\n'
                        '```json\n'
                        '{{\n'
                        '    "action": "Final Answer",\n'
                        '    "action_input": string \\ You should put what you want to return to use here\n'
                        '}}\n'
                        '```\n\n'
                        'USER\'S INPUT\n--------------------\n'
                        'Here is the user\'s input (remember to respond with a markdown code snippet of a json blob with a single '
                        'action, and NOTHING else):\n\n{input}'
                    ),
                    template_format='f-string',
                    validate_template=True
                ),
                additional_kwargs={}
            ),
            MessagesPlaceholder(variable_name='agent_scratchpad')
        ]
    ),
    llm=ChatOpenAI(
        cache=None,
        verbose=False,
        callbacks=None,
        callback_manager=None,
        tags=None,
        metadata=None,
        client=<class 'openai.api_resources.chat_completion.ChatCompletion'>,
        model_name='gpt-3.5-turbo',
        temperature=0.2,
        model_kwargs={},
        openai_api_key='PLACE API KEY HERE!!!',
        openai_api_base='',
        openai_organization='',
        openai_proxy='',
        request_timeout=None,
        max_retries=6,
        streaming=False,
        n=1,
        max_tokens=None,
        tiktoken_model_name=None
    ),
    output_key='text',
    output_parser=StrOutputParser(),
    return_final_only=True,
    llm_kwargs={},
    output_parser=ConvoOutputParser(),
    allowed_tools=['Exemplar'],
    template_tool_response=(
        "TOOL RESPONSE: \n---------------------\n{observation}\n\n"
        "USER'S INPUT\n--------------------\n\n"
        "Okay, so what is the response to my last comment? If using information obtained from the tools you must mention it explicitly "
        "without mentioning the tool names - I have forgotten all TOOL RESPONSES! Remember to respond with a markdown code snippet of "
        "a json blob with a single action, and NOTHING else."
    )
)

from langchain.prompts.chat import SystemMessagePromptTemplate

# Create a SystemMessagePromptTemplate with placeholders for variables
template = "You are a {role} assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)

# Format the template with the variables
formatted_message = system_message_prompt.format_prompt(role="helpful", input_language="English", output_language="French")

# Access the llm_chain attribute of the agent
llm_chain = agent.llm_chain

# Replace the system message in messages[0] with the formatted message
llm_chain.prompt.messages[0] = {"role": "system", "content": formatted_message}

# Old agent construction
# Initialize Agent
engagebot = initialize_agent(
    agent='chat-conversational-react-description',
    tools=tools,
    llm=llm,
    verbose=True,
    memory=conversational_memory,
    handle_parsing_errors = True,
    agent_kwargs={"format_instructions": FORMAT_INSTRUCTIONS},
    max_execution_time=10, #limits length of agent running, in seconds.
)